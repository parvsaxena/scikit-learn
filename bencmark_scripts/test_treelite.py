import treelite.gallery.sklearn
from treelite import *
from sklearn.ensemble import *
import treelite.runtime  
import csv

####### GLOBAL VARIABLES #########
num_trees = 128
dataset_path = 'cifar-10.csv'
toolchain = 'gcc'

def load_csv(filename):
    """
    Loads a csv file containin the data, parses it
    and returns numpy arrays the containing the training
    and testing data along with their labels.

    :param filename: the filename
    :return: tuple containing train, test data np arrays and labels
    """

    X_train = []
    X_test = []
    num = 0
    with open(filename,'rt')as f:
        reader = csv.reader(f, delimiter=',')
        for row in reader:
            row_int = [float(item) for item in row]
            row_int.pop()
            X_train.append(row_int)
            X_test.append(int(row[-1]))
            num+=1
            # if num > 10000:
            #     break

    #Note: we return the entire datasest and do not split into train
    #and test for now
    return X_train, X_test

if __name__ == "__main__":
    #load the data from the csv file
    print("Loading data")
    X_train, X_test = load_csv(dataset_path)

    # Train the sklearn model
    print("Fitting sklearn naive")
    clf = RandomForestClassifier(n_estimators=num_trees)
    clf.fit(X_train, X_test)

    # clf is the model object generated by scikit-learn
    model = treelite.gallery.sklearn.import_model(clf)

    #export model to shared library
    print("Generating .so")
    model.export_lib(toolchain=toolchain, libpath='./mymodel_cifar.so', verbose=True)
    params={'parallel_comp': 32}

    #predict from model using treelite's runtime predictor
    predictor = treelite.runtime.Predictor('./mymodel_cifar.so', verbose=True)
    batch = treelite.runtime.Batch.from_npy2d(X_train, rbegin=0, rend=10)
    out_pred = predictor.predict(batch)

    print(out_pred)
